{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(proc_df):\n",
    "    \n",
    "    feature_cols = proc_df.columns.to_list()\n",
    "    \n",
    "    try:\n",
    "        feature_cols.remove('Survived')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    feature_cols.remove('Name')\n",
    "    feature_cols.remove('Ticket')\n",
    "    feature_cols.remove('PassengerId')\n",
    "    \n",
    "    proc_df = proc_df[feature_cols]\n",
    "    \n",
    "    # Convert Cabin to binary\n",
    "    proc_df['Cabin'] = proc_df['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    \n",
    "    # Chane categorical values to numerical values\n",
    "    le = LabelEncoder()\n",
    "    proc_df[['Sex', 'Embarked']] = proc_df[['Sex', 'Embarked']].apply(lambda col: le.fit_transform(col.to_list()))\n",
    "    \n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    \n",
    "    imputer.fit(proc_df['Age'].values.reshape(-1, 1))\n",
    "    proc_df['Age'] = imputer.transform(proc_df['Age'].values.reshape(-1, 1))\n",
    "    \n",
    "    imputer.fit(proc_df['Fare'].values.reshape(-1, 1))\n",
    "    proc_df['Fare'] = imputer.transform(proc_df['Fare'].values.reshape(-1, 1))\n",
    "    \n",
    "    # instantiate OneHotEncoder\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "    one_hot_encode_df = proc_df[['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']]\n",
    "    one_hot_encoded_arr = ohe.fit_transform(one_hot_encode_df) # It returns an numpy array\n",
    "    column_names = ohe.get_feature_names(['Pclass', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked'])\n",
    "    one_hot_encoded_frame =  pd.DataFrame(one_hot_encoded_arr, columns=column_names.tolist())\n",
    "    \n",
    "    proc_df = pd.concat([one_hot_encoded_frame, proc_df[['Age', 'Fare']]], axis=1)\n",
    "    \n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/iso-2/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Sex_0.0</th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>SibSp_0.0</th>\n",
       "      <th>SibSp_1.0</th>\n",
       "      <th>SibSp_2.0</th>\n",
       "      <th>SibSp_3.0</th>\n",
       "      <th>SibSp_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_5.0</th>\n",
       "      <th>Parch_6.0</th>\n",
       "      <th>Cabin_0.0</th>\n",
       "      <th>Cabin_1.0</th>\n",
       "      <th>Embarked_0.0</th>\n",
       "      <th>Embarked_1.0</th>\n",
       "      <th>Embarked_2.0</th>\n",
       "      <th>Embarked_3.0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1.0  Pclass_2.0  Pclass_3.0  Sex_0.0  Sex_1.0  SibSp_0.0  SibSp_1.0  \\\n",
       "0         0.0         0.0         1.0      0.0      1.0        0.0        1.0   \n",
       "1         1.0         0.0         0.0      1.0      0.0        0.0        1.0   \n",
       "2         0.0         0.0         1.0      1.0      0.0        1.0        0.0   \n",
       "3         1.0         0.0         0.0      1.0      0.0        0.0        1.0   \n",
       "4         0.0         0.0         1.0      0.0      1.0        1.0        0.0   \n",
       "\n",
       "   SibSp_2.0  SibSp_3.0  SibSp_4.0  ...  Parch_5.0  Parch_6.0  Cabin_0.0  \\\n",
       "0        0.0        0.0        0.0  ...        0.0        0.0        1.0   \n",
       "1        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0  ...        0.0        0.0        1.0   \n",
       "3        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0  ...        0.0        0.0        1.0   \n",
       "\n",
       "   Cabin_1.0  Embarked_0.0  Embarked_1.0  Embarked_2.0  Embarked_3.0   Age  \\\n",
       "0        0.0           0.0           0.0           1.0           0.0  22.0   \n",
       "1        1.0           1.0           0.0           0.0           0.0  38.0   \n",
       "2        0.0           0.0           0.0           1.0           0.0  26.0   \n",
       "3        1.0           0.0           0.0           1.0           0.0  35.0   \n",
       "4        0.0           0.0           0.0           1.0           0.0  35.0   \n",
       "\n",
       "      Fare  \n",
       "0   7.2500  \n",
       "1  71.2833  \n",
       "2   7.9250  \n",
       "3  53.1000  \n",
       "4   8.0500  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Survived']\n",
    "x = preprocessing(df)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9854096520763187\n"
     ]
    }
   ],
   "source": [
    "# Run the Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='gini')\n",
    "rf.fit(x, y)\n",
    "\n",
    "print(rf.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/iso-2/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1.0</th>\n",
       "      <th>Pclass_2.0</th>\n",
       "      <th>Pclass_3.0</th>\n",
       "      <th>Sex_0.0</th>\n",
       "      <th>Sex_1.0</th>\n",
       "      <th>SibSp_0.0</th>\n",
       "      <th>SibSp_1.0</th>\n",
       "      <th>SibSp_2.0</th>\n",
       "      <th>SibSp_3.0</th>\n",
       "      <th>SibSp_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_5.0</th>\n",
       "      <th>Parch_6.0</th>\n",
       "      <th>Parch_9.0</th>\n",
       "      <th>Cabin_0.0</th>\n",
       "      <th>Cabin_1.0</th>\n",
       "      <th>Embarked_0.0</th>\n",
       "      <th>Embarked_1.0</th>\n",
       "      <th>Embarked_2.0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1.0  Pclass_2.0  Pclass_3.0  Sex_0.0  Sex_1.0  SibSp_0.0  SibSp_1.0  \\\n",
       "0         0.0         0.0         1.0      0.0      1.0        1.0        0.0   \n",
       "1         0.0         0.0         1.0      1.0      0.0        0.0        1.0   \n",
       "2         0.0         1.0         0.0      0.0      1.0        1.0        0.0   \n",
       "3         0.0         0.0         1.0      0.0      1.0        1.0        0.0   \n",
       "4         0.0         0.0         1.0      1.0      0.0        0.0        1.0   \n",
       "\n",
       "   SibSp_2.0  SibSp_3.0  SibSp_4.0  ...  Parch_5.0  Parch_6.0  Parch_9.0  \\\n",
       "0        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0  ...        0.0        0.0        0.0   \n",
       "\n",
       "   Cabin_0.0  Cabin_1.0  Embarked_0.0  Embarked_1.0  Embarked_2.0   Age  \\\n",
       "0        1.0        0.0           0.0           1.0           0.0  34.5   \n",
       "1        1.0        0.0           0.0           0.0           1.0  47.0   \n",
       "2        1.0        0.0           0.0           1.0           0.0  62.0   \n",
       "3        1.0        0.0           0.0           0.0           1.0  27.0   \n",
       "4        1.0        0.0           0.0           0.0           1.0  22.0   \n",
       "\n",
       "      Fare  \n",
       "0   7.8292  \n",
       "1   7.0000  \n",
       "2   9.6875  \n",
       "3   8.6625  \n",
       "4  12.2875  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets predict for test csv given to us\n",
    "x_test = pd.read_csv('test.csv')\n",
    "\n",
    "passenger_id = x_test['PassengerId']\n",
    "x_test = preprocessing(x_test)\n",
    "\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([passenger_id, pd.DataFrame(rf.predict(x_test))], axis=1)\n",
    "final_df.columns = ['PassengerId', 'Survived']\n",
    "final_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800], 'max_depth': [50, 100, 150, 200, 250, 300, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 800, num = 8)]\n",
    "\n",
    "# criterion\n",
    "# criterion = ['gini', 'entropy']\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(50, 300, num = 6)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "#                'criterion': criterion,\n",
    "#                'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1008 candidates, totalling 5040 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 537 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 570 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 605 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 677 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 714 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 753 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 833 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 874 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 917 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1050 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1097 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1193 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1344 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1397 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1505 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1617 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1674 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1733 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1853 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1914 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2105 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2170 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2237 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2304 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2373 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2513 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2657 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2730 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2805 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2880 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2957 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3034 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3113 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3354 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3437 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3520 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3605 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3690 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3777 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3953 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4133 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4224 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4317 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4410 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4505 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4697 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4794 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5040 out of 5040 | elapsed: 26.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [50, 100, 150, 200, 250, 300, None],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500, 600, 700,\n",
       "                                          800]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rfclf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator=rfclf, param_grid=random_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=10)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_grid = pd.concat([passenger_id, pd.DataFrame(rf_random.predict(x_test))], axis=1)\n",
    "final_df_grid.columns = ['PassengerId', 'Survived']\n",
    "final_df_grid.to_csv('submission_grid.csv', index=False)\n",
    "\n",
    "final_df_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
